# 오차제곱합 sum of square error
# 손실함수는 신경망 성능의 나쁨을 나타내는 지표이다. 현재 신경망이 훈련데이터를 얼마나 잘 처리하는지 나타낸다. 
# 손실함수를 사용하으로써 신경망이 높은 정확도를 끌어내기 위한 매개변수를 찾기 위함이다. 
# t는 정답레이블, y는 추정치이다. 
# y 는 소프트맥스 함수의 출력으로 0~1 사이의 값을 나타내는데 이는 정답레이블과 매칭될 확률로 해석할 수 있다.
# 코드에서 y = 0.1 이면 해당 y의 인덱스값이 같은 t 의 레이블 0 이 발생할 확률이 0.1 이라고 할 수 있다. 
# 아래 코드는 정답 t 에 대한 추정치를 임의로 설정하여 오차제곱합을 계산한다
# 값이 낮을 수록 오차가 작다는 뜻이다. 
import numpy as np

def sum_square_error(y,t):
    return 0.5 * np.sum((y-t)**2)
# 정답은 t의 인덱스 2
# 정답인 원소만 1 아는 원소는 0
t = [0,0,1,0,0,0,0,0,0,0]
# 정답에 해당하는 인덱스의 확률이 가장 높을 때
y = [0.1,0.05,0.6,0.0,0.05,0.1,0.0,0.1,0.0,0.0]
print(sum_square_error(np.array(y), np.array(t)))
# 정답에 대당하는 인덱스 확률을 잘목 예측했을 때 
y2 = [0.1,0.05,0.1,0.0,0.05,0.1,0.0,0.6,0.0,0.0]
print(sum_square_error(np.array(y2), np.array(t)))